{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for texture synthesis for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the transform to convert the images to tensors and normalize them\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts image to PyTorch tensor\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist_train = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_test = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "DATASET_IMAGES = 10000\n",
    "TESTSET_IMAGES = 500\n",
    "# DataLoader\n",
    "train_loader = DataLoader(mnist_train, batch_size=DATASET_IMAGES, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=TESTSET_IMAGES, shuffle=False)\n",
    " \n",
    "# Move the data to the specified device (GPU 0)\n",
    "training_images, training_labels = next(iter(train_loader))\n",
    "test_images, test_labels = next(iter(test_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define input args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from synthesis_mnist import *\n",
    "\n",
    "window_size=(28,28)         # Generated image size, (height,width)\n",
    "kernel_size=5               # history window size\n",
    "seed_size=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current window size: torch.Size([7, 7])\n"
     ]
    }
   ],
   "source": [
    "synthesized_texture = synthesize_texture(sample=training_images,\n",
    "                                         test_sample=test_images,\n",
    "                                         window_size=window_size, \n",
    "                                         kernel_size=kernel_size, \n",
    "                                         seed_size=seed_size)\n",
    "\n",
    "current_time = datetime.datetime.now()\n",
    "formatted_time = current_time.strftime(\"%m-%d_%H:%M:%S\")  # Format: month-day hour:minute\n",
    "out_path=f'outputs/mnist/{formatted_time}.png'\n",
    "\n",
    "fig, [ax1, ax2] = plt.subplots(1,2)\n",
    "ax2.imshow(synthesized_texture.to('cpu'), vmin=0, vmax=1, cmap='grey')\n",
    "ax2.set(title=f'result. kernel={kernel_size}x{kernel_size}')\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "\n",
    "# Place seed in center of window\n",
    "\n",
    "ph, pw = (window_size[0] - seed_size + 1) // 2, (window_size[1] - seed_size + 1) // 2\n",
    "original_seed = synthesized_texture[ph:ph+seed_size, pw:pw+seed_size]\n",
    "ax1.imshow(original_seed.to('cpu'), vmin=0, vmax=1, cmap='grey')\n",
    "ax1.set(title=f'seed. Time: {formatted_time}')\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "fig.savefig(out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
